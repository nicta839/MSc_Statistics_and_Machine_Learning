{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "TM-L4_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24bXF1_wcR6e"
      },
      "source": [
        "# L4: Word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdgdZyVqcR6k"
      },
      "source": [
        "In this lab you will explore word embeddings. A **word embedding** is a mapping of words to points in a vector space such that nearby words (points) are similar in terms of their distributional properties. You will use word embedding to find similar words, and evaluate their usefulness in an inference task.\n",
        "\n",
        "You will use the word vectors that come with [spaCy](http://spacy.io). Note that you will need the &lsquo;large&rsquo; English language model; the &lsquo;small&rsquo; model that you used in previous labs does not include proper word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcVVhHdscU-4",
        "outputId": "6d9c697e-f793-4a57-8ad2-103e36e17462"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNQZlejEcW0C",
        "outputId": "c8e742bf-edc8-435a-d240-6305127f5214"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/l4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/l4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjxrG37nclkT"
      },
      "source": [
        "# !python -m spacy download en_core_web_lg "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70-Ha_x7cR6l"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JG4YGQScR6m"
      },
      "source": [
        "Every word in the model&rsquo;s vocabulary comes with a 300-dimensional vector, represented as a NumPy array. The following code cell shows how to access the vector for the word *cheese*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DYsN0KQcR6n",
        "outputId": "8126e6ac-5d2b-4c0d-8848-9396fd14a7f7"
      },
      "source": [
        "nlp.vocab['cheese'].vector"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.5252e-01,  1.8894e-01,  6.8737e-01, -1.9789e-01,  7.0575e-02,\n",
              "        1.0075e+00,  5.1789e-02, -1.5603e-01,  3.1941e-01,  1.1702e+00,\n",
              "       -4.7248e-01,  4.2867e-01, -4.2025e-01,  2.4803e-01,  6.8194e-01,\n",
              "       -6.7488e-01,  9.2401e-02,  1.3089e+00, -3.6278e-02,  2.0098e-01,\n",
              "        7.6005e-01, -6.6718e-02, -7.7794e-02,  2.3844e-01, -2.4351e-01,\n",
              "       -5.4164e-01, -3.3540e-01,  2.9805e-01,  3.5269e-01, -8.0594e-01,\n",
              "       -4.3611e-01,  6.1535e-01,  3.4212e-01, -3.3603e-01,  3.3282e-01,\n",
              "        3.8065e-01,  5.7427e-02,  9.9918e-02,  1.2525e-01,  1.1039e+00,\n",
              "        3.6678e-02,  3.0490e-01, -1.4942e-01,  3.2912e-01,  2.3300e-01,\n",
              "        4.3395e-01,  1.5666e-01,  2.2778e-01, -2.5830e-02,  2.4334e-01,\n",
              "       -5.8136e-02, -1.3486e-01,  2.4521e-01, -3.3459e-01,  4.2839e-01,\n",
              "       -4.8181e-01,  1.3403e-01,  2.6049e-01,  8.9933e-02, -9.3770e-02,\n",
              "        3.7672e-01, -2.9558e-02,  4.3841e-01,  6.1212e-01, -2.5720e-01,\n",
              "       -7.8506e-01,  2.3880e-01,  1.3399e-01, -7.9315e-02,  7.0582e-01,\n",
              "        3.9968e-01,  6.7779e-01, -2.0474e-03,  1.9785e-02, -4.2059e-01,\n",
              "       -5.3858e-01, -5.2155e-02,  1.7252e-01,  2.7547e-01, -4.4482e-01,\n",
              "        2.3595e-01, -2.3445e-01,  3.0103e-01, -5.5096e-01, -3.1159e-02,\n",
              "       -3.4433e-01,  1.2386e+00,  1.0317e+00, -2.2728e-01, -9.5207e-03,\n",
              "       -2.5432e-01, -2.9792e-01,  2.5934e-01, -1.0421e-01, -3.3876e-01,\n",
              "        4.2470e-01,  5.8335e-04,  1.3093e-01,  2.8786e-01,  2.3474e-01,\n",
              "        2.5905e-02, -6.4359e-01,  6.1330e-02,  6.3842e-01,  1.4705e-01,\n",
              "       -6.1594e-01,  2.5097e-01, -4.4872e-01,  8.6825e-01,  9.9555e-02,\n",
              "       -4.4734e-02, -7.4239e-01, -5.9147e-01, -5.4929e-01,  3.8108e-01,\n",
              "        5.5177e-02, -1.0487e-01, -1.2838e-01,  6.0521e-03,  2.8743e-01,\n",
              "        2.1592e-01,  7.2871e-02, -3.1644e-01, -4.3321e-01,  1.8682e-01,\n",
              "        6.7274e-02,  2.8115e-01, -4.6222e-02, -9.6803e-02,  5.6091e-01,\n",
              "       -6.7762e-01, -1.6645e-01,  1.5553e-01,  5.2301e-01, -3.0058e-01,\n",
              "       -3.7291e-01,  8.7895e-02, -1.7963e-01, -4.4193e-01, -4.4607e-01,\n",
              "       -2.4122e+00,  3.3738e-01,  6.2416e-01,  4.2787e-01, -2.5386e-01,\n",
              "       -6.1683e-01, -7.0097e-01,  4.9303e-01,  3.6916e-01, -9.7499e-02,\n",
              "        6.1411e-01, -4.7572e-03,  4.3916e-01, -2.1551e-01, -5.6745e-01,\n",
              "       -4.0278e-01,  2.9459e-01, -3.0850e-01,  1.0103e-01,  7.9741e-02,\n",
              "       -6.3811e-01,  2.4781e-01, -4.4546e-01,  1.0828e-01, -2.3624e-01,\n",
              "       -5.0838e-01, -1.7001e-01, -7.8735e-01,  3.4073e-01, -3.1830e-01,\n",
              "        4.5286e-01, -9.5118e-02,  2.0772e-01, -8.0183e-02, -3.7982e-01,\n",
              "       -4.9949e-01,  4.0759e-02, -3.7724e-01, -8.9705e-02, -6.8187e-01,\n",
              "        2.2106e-01, -3.9931e-01,  3.2329e-01, -3.6180e-01, -7.2093e-01,\n",
              "       -6.3404e-01,  4.3125e-01, -4.9743e-01, -1.7395e-01, -3.8779e-01,\n",
              "       -3.2556e-01,  1.4423e-01, -8.3401e-02, -2.2994e-01,  2.7793e-01,\n",
              "        4.9112e-01,  6.4511e-01, -7.8945e-02,  1.1171e-01,  3.7264e-01,\n",
              "        1.3070e-01, -6.1607e-02, -4.3501e-01,  2.8999e-02,  5.6224e-01,\n",
              "        5.8012e-02,  4.7078e-02,  4.2770e-01,  7.3245e-01, -2.1150e-02,\n",
              "        1.1988e-01,  7.8823e-02, -1.9106e-01,  3.5278e-02, -3.1102e-01,\n",
              "        1.3209e-01, -2.8606e-01, -1.5649e-01, -6.4339e-01,  4.4599e-01,\n",
              "       -3.0912e-01,  4.4520e-01, -3.6774e-01,  2.7327e-01,  6.7833e-01,\n",
              "       -8.3830e-02, -4.5120e-01,  1.0754e-01, -4.5908e-01,  1.5095e-01,\n",
              "       -4.5856e-01,  3.4465e-01,  7.8013e-02, -2.8319e-01, -2.8149e-02,\n",
              "        2.4404e-01, -7.1345e-01,  5.2834e-02, -2.8085e-01,  2.5344e-02,\n",
              "        4.2979e-02,  1.5663e-01, -7.4647e-01, -1.1301e+00,  4.4135e-01,\n",
              "        3.1444e-01, -1.0018e-01, -5.3526e-01, -9.0601e-01, -6.4954e-01,\n",
              "        4.2664e-02, -7.9927e-02,  3.2905e-01, -3.0797e-01, -1.9190e-02,\n",
              "        4.2765e-01,  3.1460e-01,  2.9051e-01, -2.7386e-01,  6.8483e-01,\n",
              "        1.9395e-02, -3.2884e-01, -4.8239e-01, -1.5747e-01, -1.6036e-01,\n",
              "        4.9164e-01, -7.0352e-01, -3.5591e-01, -7.4887e-01, -5.2827e-01,\n",
              "        4.4983e-02,  5.9247e-02,  4.6224e-01,  8.9697e-02, -7.5618e-01,\n",
              "        6.3682e-01,  9.0680e-02,  6.8830e-02,  1.8296e-01,  1.0754e-01,\n",
              "        6.7811e-01, -1.4716e-01,  1.7029e-01, -5.2630e-01,  1.9268e-01,\n",
              "        9.3130e-01,  8.0363e-01,  6.1324e-01, -3.0494e-01,  2.0236e-01,\n",
              "        5.8520e-01,  2.6484e-01, -4.5863e-01,  2.1035e-03, -5.6990e-01,\n",
              "       -4.9092e-01,  4.2511e-01, -1.0954e+00,  1.7124e-01,  2.2495e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Znn8iFaVcR6o"
      },
      "source": [
        "## Problem 1: Finding similar words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuP1qD9fcR6p"
      },
      "source": [
        "Your first task is to use the word embeddings to find similar words. More specifically, we ask you to write a function `most_similar` that takes a vector $x$ and returns a list with the 10 most similar entries in spaCy&rsquo;s vocabulary, with similarity being defined by cosine.\n",
        "\n",
        "**Tip:** spaCy already has a [`most_similar`](https://spacy.io/api/vectors#most_similar) method that you can wrap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erTXj1qkcR6r"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elA3H4pbcR6s"
      },
      "source": [
        "# TODO: Enter your implementation of `most_similar` here\n",
        "def most_similar(x):\n",
        "    queries = np.array([x])\n",
        "    similar_vocab_entries = nlp.vocab.vectors.most_similar(queries=queries, n=10)[0][0]\n",
        "    return([nlp.vocab[entry] for entry in similar_vocab_entries])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4M5k-zKcR6t"
      },
      "source": [
        "Test your implementation by running the following code cell, which will print the 10 most similar words for the word *cheese*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Envyh-QcR6u",
        "outputId": "d43c8a09-2638-442f-d6bf-fbd01e0de174"
      },
      "source": [
        "print(' '.join(w.text for w in most_similar(nlp.vocab['cheese'].vector)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cheese CHEESE cheese Cheddar cheddar CHEDDAR BACON Bacon bacon cheeses\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSwtbcwucR6u"
      },
      "source": [
        "You should get the following output:"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "5PcTAh1EcR6u"
      },
      "source": [
        "CHEESE cheese Cheese Cheddar cheddar CHEDDAR BACON Bacon bacon cheeses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK9vsNhycR6v"
      },
      "source": [
        "Once you have a working implementation of `most_similar`, use it to think about in what sense the returned words really are &lsquo;similar&rsquo; to the cue word. Try to find examples where the cue word and at least one of the words returned by `most_similar` are in the following semantic relations:\n",
        "\n",
        "1. synonymy (exchangeable meanings)\n",
        "2. antonymy (opposite meanings)\n",
        "3. hyperonymy/hyponymy (more specific/less specific meanings)\n",
        "\n",
        "Document your examples in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpEpO3bocR6v",
        "outputId": "71515cab-a5b6-4239-f5f5-cdd4abcc823d"
      },
      "source": [
        "# TODO: Insert code here to generate your examples\n",
        "\n",
        "# Synonymy\n",
        "print(\"Synonymy\")\n",
        "print(\"#\" * 100)\n",
        "print(' '.join(w.text for w in most_similar(nlp.vocab['concerning'].vector)))\n",
        "print(\"#\" * 100, \"\\n\")\n",
        "\n",
        "# Antonymy\n",
        "print(\"Antonymy\")\n",
        "print(\"#\" * 100)\n",
        "print(' '.join(w.text for w in most_similar(nlp.vocab['mom'].vector)))\n",
        "print(\"#\" * 100, \"\\n\")\n",
        "\n",
        "# Hyperonymy\n",
        "print(\"Hyperonymy\")\n",
        "print(\"#\" * 100)\n",
        "print(' '.join(w.text for w in most_similar(nlp.vocab['animal'].vector)))\n",
        "print(\"#\" * 100, \"\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonymy\n",
            "####################################################################################################\n",
            "concerning Concerning CONCERNING Regarding regarding REGARDING relating RELATING Relating PERTAINING\n",
            "#################################################################################################### \n",
            "\n",
            "Antonymy\n",
            "####################################################################################################\n",
            "MOM Mom MoM mom DAD DaD Dad dad Grandma GRANDMA\n",
            "#################################################################################################### \n",
            "\n",
            "Hyperonymy\n",
            "####################################################################################################\n",
            "Animal ANIMAL animal animals ANIMALS Animals pet Pet PET doG\n",
            "#################################################################################################### \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WfRZxKlcR6w"
      },
      "source": [
        "## Problem 2: Plotting similar words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRAdHHEecR6w"
      },
      "source": [
        "Your next task is to visualize the word embedding space by a plot. To do so, you will have to reduce the dimensionality of the space from 300 to 2&nbsp;dimensions. One suitable algorithm for this is [T-distributed Stochastic Neighbor Embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) (TSNE), which is implemented in scikit-learn&rsquo;s [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) class.\n",
        "\n",
        "Write a function `plot_most_similar` that takes a list of words (lexemes) and does the following:\n",
        "\n",
        "1. For each word in the list, find the most similar words (lexemes) in the spaCy vocabulary.\n",
        "2. Compute the TSNE transformation of the corresponding vectors to 2&nbsp;dimensions.\n",
        "3. Produce a scatter plot of the transformed vectors, with the vectors as points and the corresponding word forms as labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5ccj4z8cR6x"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0QrmWvXcR6x"
      },
      "source": [
        "# TODO: Write code here to plot the most similar words\n",
        "\n",
        "def plot_most_similar(words):\n",
        "    # 1. For each word in the list, find the most similar words (lexemes) in the spaCy vocabulary.\n",
        "    lexemes = np.array([most_similar(word.vector) for word in words]).flatten()\n",
        "    \n",
        "    # 2. Compute the TSNE transformation of the corresponding vectors to 2 dimensions.\n",
        "    X = [lexeme.vector for lexeme in lexemes]\n",
        "    X_embedded = TSNE(n_components=2).fit_transform(X)\n",
        "   \n",
        "    # 3. Produce a scatter plot of the transformed vectors, with the vectors as points and the corresponding word forms as labels.\n",
        "    x_coords = X_embedded[:, 0]\n",
        "    y_coords = X_embedded[:, 1]\n",
        "    plt.scatter(x_coords, y_coords)\n",
        "    for label, x, y in zip([lex.text for lex in lexemes], x_coords, y_coords):\n",
        "        plt.annotate(label, (x,y), xytext=(0, 0), textcoords=\"offset points\", ha=\"center\", va=\"center\")\n",
        "    plt.title(\"Visualizing Word Embedding Space\")\n",
        "    plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wF24ABQcR6x"
      },
      "source": [
        "Test your code by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "h2bL74DPcR6y",
        "outputId": "cb3da124-9eea-447f-8167-de476aa4a873"
      },
      "source": [
        "plot_most_similar([nlp.vocab[w] for w in ['cheese', 'goat', 'sweden', 'university', 'computer']])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw8WcqwUcR6y"
      },
      "source": [
        "Take a few minutes to look at your plot. What does it tell you? What does it *not* tell you?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jPEuS6ocR6y"
      },
      "source": [
        "## Problem 3: Analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K7KdF67cR6z"
      },
      "source": [
        "In a **word analogy task** you are given three words $x$, $y$, $z$ and have to predict a word $w$ that has the same semantic relation to $z$ as $y$ has to $x$. One example is *man*, *woman*, *brother*, the expected answer being *sister* (the semantic relation is *male*/*female*).\n",
        "\n",
        "[Mikolov et al. (2013)](http://www.aclweb.org/anthology/N13-1090) have shown that some types of word analogy tasks can be solved by adding and substracting word vectors in a word embedding: the vector for *sister* is the closest vector (in terms of cosine distance) to the vector *brother* $-$ *man* $+$ *woman*. Your next task is to write a function `fourth` that takes in three words (say *brother*, *man*, *woman*) and predicts the word that completes the analogy (in this case, *sister*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C53Q9ZKbcR6z"
      },
      "source": [
        "# TODO: Enter code here to solve the analogy problem\n",
        "def fourth(x, y, z):\n",
        "    analogy = most_similar((x.vector - y.vector + z.vector))[0]\n",
        "    return (analogy)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fKwUw9DcR6z"
      },
      "source": [
        "Test your code by running the following code. You should get *sister*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5XrVKeTbcR60",
        "outputId": "0712fed8-739d-4d85-c70a-ad4db71efd2e"
      },
      "source": [
        "fourth(nlp.vocab['brother'], nlp.vocab['man'], nlp.vocab['woman']).text"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SISTER'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HPpVanD2cR60",
        "outputId": "80f01436-2369-4366-f28e-b698b077270e"
      },
      "source": [
        "fourth(nlp.vocab['Stockholm'], nlp.vocab['Sweden'], nlp.vocab['Germany']).text"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'BERLIN'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K1zl3km-cR61",
        "outputId": "054c6255-63f2-4218-b3db-e44e803cd16a"
      },
      "source": [
        "fourth(nlp.vocab['Swedish'], nlp.vocab['Sweden'], nlp.vocab['France']).text"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'French'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Mk5yYcnPcR61",
        "outputId": "c57151d4-2761-4d63-a145-fd68ac8505c6"
      },
      "source": [
        "fourth(nlp.vocab['better'], nlp.vocab['good'], nlp.vocab['bad']).text"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'WORSE'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fb5synz9cR61",
        "outputId": "3b1cea53-48e4-4357-b4ca-ca60579ec6c1"
      },
      "source": [
        "fourth(nlp.vocab['walked'], nlp.vocab['walk'], nlp.vocab['take']).text"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TOOK'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf32Q4otcR62"
      },
      "source": [
        "You should also be able to get the following:\n",
        "\n",
        "* *Stockholm* $-$ *Sweden* $+$ *Germany* $=$ *Berlin*\n",
        "* *Swedish* $-$ *Sweden* $+$ *France* $=$ *French*\n",
        "* *better* $-$ *good* $+$ *bad* $=$ *worse*\n",
        "* *walked* $-$ *walk* $+$ *take* $=$ *took*\n",
        "\n",
        "Experiment with other examples to see whether you get the expected output. Provide three examples of analogies for which the model produces the &lsquo;correct&rsquo; answer, and three examples on which the model &lsquo;failed&rsquo;. Based on your theoretical understanding of word embeddings, do you have a hypothesis as to why the model succeeds/fails in completing the analogy? Discuss this question in a short text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLBqvwyycR62"
      },
      "source": [
        "**Examples: Success**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "INTMHlJ7cR62",
        "outputId": "1b1ac9af-f55c-4abe-dbc2-12eb853333b9"
      },
      "source": [
        "fourth(nlp.vocab['swimming'], nlp.vocab['Swimmer'], nlp.vocab['Skier']).text"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SKIING'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "C6YGKUEkcR62",
        "outputId": "520d05c8-3de8-4987-aa00-780dd7806866"
      },
      "source": [
        "fourth(nlp.vocab['0am'], nlp.vocab['midnight'], nlp.vocab['midday']).text"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0am'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Ks_bCtDJcR63",
        "outputId": "54044a66-3559-4858-8503-9eed4ffec551"
      },
      "source": [
        "fourth(nlp.vocab['cat'], nlp.vocab['cats'], nlp.vocab['dogs']).text"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Dog'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrEyn-rycR63"
      },
      "source": [
        "**Examples: Failure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "e-945Yv5cR63",
        "outputId": "1b34ce55-a49c-4a27-cf55-fcba9244931f"
      },
      "source": [
        "fourth(nlp.vocab['son'], nlp.vocab['father'], nlp.vocab['mother']).text"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'son'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SBiiVvK2cR64",
        "outputId": "4d534a98-0f81-4083-a0e4-b1facde6eef2"
      },
      "source": [
        "fourth(nlp.vocab['playstation'], nlp.vocab['sony'], nlp.vocab['microsoft']).text"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MicroSoft'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "my7v6gGZcR64",
        "outputId": "890f4845-7866-4394-b716-892d163eb6c0"
      },
      "source": [
        "fourth(nlp.vocab['old'], nlp.vocab['parents'], nlp.vocab['kids']).text"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'old'"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZeWb9gcR64"
      },
      "source": [
        "**Answer:**\n",
        "\n",
        "In general, the model doesn't succeed that often. It took us a long time to even find 3 working examples. It is way easier to find examples that don't work out. Given that each word is represented as a vector and we know that similar words point in the same direction we think it is easier to find correct analogies if the words x and are similar. If, on the other hand, our 2 base words differ a lot, we expect a higher chance of false predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2k6Plu2cR65"
      },
      "source": [
        "## Natural language inference dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaZ2twqdcR65"
      },
      "source": [
        "In the second part of this lab, you will be evaluating the usefulness of word embeddings in the context of a natural language inference task. The data for this part is the [SNLI corpus](https://nlp.stanford.edu/projects/snli/), a collection of 570k human-written English image caption pairs manually labeled with the labels *Entailment*, *Contradiction*, and *Neutral*. Consider the following sentence pair as an example:\n",
        "\n",
        "* Sentence 1: A soccer game with multiple males playing.\n",
        "* Sentence 2: Some men are playing a sport.\n",
        "\n",
        "This pair is labeled with *Entailment*, because sentence&nbsp;2 is logically entailed (implied) by sentence&nbsp;1 – if sentence&nbsp;1 is true, then sentence&nbsp;2 is true, too. The following sentence pair, on the other hand, is labeled with *Contradiction*, because both sentences cannot be true at the same time.\n",
        "\n",
        "* Sentence 1: A black race car starts up in front of a crowd of people.\n",
        "* Sentence 2: A man is driving down a lonely road.\n",
        "\n",
        "For detailed information about the corpus, refer to [Bowman et al. (2015)](https://www.aclweb.org/anthology/D15-1075/). For this lab, we load the training portion and the development portion of the dataset.\n",
        "\n",
        "**Note:** Because the SNLI corpus is rather big, we initially only load a small portion (25,000 samples) of the training data. Once you have working code for Problems&nbsp;4–6, you should set the flag `final` to `True` and re-run all cells with the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce3cHplZcR68",
        "outputId": "795f0443-06b2-4521-d6fd-a6396dc803a6"
      },
      "source": [
        "import bz2\n",
        "import pandas as pd\n",
        "\n",
        "final_evaluation = False    # TODO: Set to True for the final evaluation!\n",
        "\n",
        "with bz2.open('train.jsonl.bz2', 'rt') as source:\n",
        "    if final_evaluation:\n",
        "        df_train = pd.read_json(source, lines=True)\n",
        "    else:\n",
        "        df_train = pd.read_json(source, lines=True, nrows=25000)\n",
        "    print('Number of sentence pairs in the training data:', len(df_train))\n",
        "\n",
        "with bz2.open('dev.jsonl.bz2', 'rt') as source:\n",
        "    df_dev = pd.read_json(source, lines=True)\n",
        "    print('Number of sentence pairs in the development data:', len(df_dev))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentence pairs in the training data: 25000\n",
            "Number of sentence pairs in the development data: 9842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq1b_j-TcR69"
      },
      "source": [
        "When you inspect the data frames, you will see that we have preprocessed the sentences and separated tokens by spaces. In the columns `tagged1` and `tagged2`, we have added the part-of-speech tags for every token (as predicted by spaCy), also separated by spaces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mynhlJgKcR6-",
        "outputId": "1b129505-7306-4163-8741-e54838d359c1"
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>tags1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>tags2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>NUM NOUN AUX VERB SCONJ VERB PART VERB NOUN PUNCT</td>\n",
              "      <td>The sisters are hugging goodbye while holding ...</td>\n",
              "      <td>DET NOUN AUX VERB NOUN SCONJ VERB PART VERB NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>entailment</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>NUM NOUN AUX VERB SCONJ VERB PART VERB NOUN PUNCT</td>\n",
              "      <td>Two woman are holding packages .</td>\n",
              "      <td>NUM NOUN AUX VERB NOUN PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>Two women are embracing while holding to go pa...</td>\n",
              "      <td>NUM NOUN AUX VERB SCONJ VERB PART VERB NOUN PUNCT</td>\n",
              "      <td>The men are fighting outside a deli .</td>\n",
              "      <td>DET NOUN AUX VERB ADP DET NOUN PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>entailment</td>\n",
              "      <td>Two young children in blue jerseys , one with ...</td>\n",
              "      <td>NUM ADJ NOUN ADP ADJ NOUN PUNCT NUM ADP DET NO...</td>\n",
              "      <td>Two kids in numbered jerseys wash their hands .</td>\n",
              "      <td>NUM NOUN ADP ADJ NOUN VERB PRON NOUN PUNCT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Two young children in blue jerseys , one with ...</td>\n",
              "      <td>NUM ADJ NOUN ADP ADJ NOUN PUNCT NUM ADP DET NO...</td>\n",
              "      <td>Two kids at a ballgame wash their hands .</td>\n",
              "      <td>NUM NOUN ADP DET NOUN VERB PRON NOUN PUNCT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gold_label  ...                                              tags2\n",
              "0        neutral  ...  DET NOUN AUX VERB NOUN SCONJ VERB PART VERB NO...\n",
              "1     entailment  ...                       NUM NOUN AUX VERB NOUN PUNCT\n",
              "2  contradiction  ...               DET NOUN AUX VERB ADP DET NOUN PUNCT\n",
              "3     entailment  ...         NUM NOUN ADP ADJ NOUN VERB PRON NOUN PUNCT\n",
              "4        neutral  ...         NUM NOUN ADP DET NOUN VERB PRON NOUN PUNCT\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q38TDbqrcR7E"
      },
      "source": [
        "## Problem 4: Two simple baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7gFZvyxcR7E"
      },
      "source": [
        "Your first task is to establish two simple baselines for the natural language inference task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KR_ZWl5cR7F"
      },
      "source": [
        "### Random baseline\n",
        "\n",
        "Implement the standard random baseline that generates prediction by sampling from the empirical distribution of the classes in the training data. Write code to evaluate the performance of this classifier on the development data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSlBUFK_fyU6"
      },
      "source": [
        "# import from sklearn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import itertools\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9v-L_n-gEdq"
      },
      "source": [
        "# function to predict from a model given train and test data\n",
        "def predictions(model, datasets):\n",
        "  return(model.predict(data) for data in datasets)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-OtD166cR7F"
      },
      "source": [
        "# TODO: Enter code here to implement the random baseline. Print the classification report.\n",
        "dummy_class = DummyClassifier().fit(df_train.loc[:, df_train.columns != \"gold_label\"], df_train[\"gold_label\"])\n",
        "train_predict, dev_predict = predictions(dummy_class, [df_train.loc[:, df_train.columns != \"gold_label\"], df_dev.loc[:, df_dev.columns != \"gold_label\"]])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "hi3YHctkjC9R",
        "outputId": "a1ba0747-63c3-432c-d458-6dab94f066db"
      },
      "source": [
        "pd.DataFrame(classification_report(train_predict, df_train[\"gold_label\"], output_dict=True))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33388</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333880</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33388</td>\n",
              "      <td>0.111293</td>\n",
              "      <td>0.333880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500615</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33388</td>\n",
              "      <td>0.166872</td>\n",
              "      <td>0.500615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>0.0</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.33388</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction    entailment  ...     macro avg  weighted avg\n",
              "precision            0.0      1.000000  ...      0.333333      1.000000\n",
              "recall               0.0      0.333880  ...      0.111293      0.333880\n",
              "f1-score             0.0      0.500615  ...      0.166872      0.500615\n",
              "support              0.0  25000.000000  ...  25000.000000  25000.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "6k77uOlXjm4o",
        "outputId": "f9f045ed-2a58-4732-c5c9-2e5a859344b2"
      },
      "source": [
        "pd.DataFrame(classification_report(dev_predict, df_dev[\"gold_label\"], output_dict=True))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.112748</td>\n",
              "      <td>0.338244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.505505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.168502</td>\n",
              "      <td>0.505505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>0.0</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision            0.0     1.000000  ...     0.333333      1.000000\n",
              "recall               0.0     0.338244  ...     0.112748      0.338244\n",
              "f1-score             0.0     0.505505  ...     0.168502      0.505505\n",
              "support              0.0  9842.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ba4JKvGcR7F"
      },
      "source": [
        "### One-sided baseline\n",
        "\n",
        "A second obvious baseline for the inference task is to predict the class label of a sentence pair based on the text of only one of the two sentences, just as in a standard document classification task. Put together a simple [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) + [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) pipeline that implements this idea, train it, and evaluate it on the development data. Is it better to base predictions on sentence&nbsp;1 or sentence&nbsp;2? Why should one sentence be more useful than the other?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSZtVBzScR7F"
      },
      "source": [
        "# TODO: Enter code here to implement the one-sentence baselines. Print the classification reports.\n",
        "cntvectorizer = CountVectorizer(ngram_range=(1,2), min_df = 4, max_df=0.9)\n",
        "logreg = LogisticRegression(solver=\"saga\", multi_class=\"ovr\", max_iter=100)\n",
        "\n",
        "cntlog_pipeline = Pipeline([(\"cnt_vectorizer\", cntvectorizer), (\"LogisticRegression\", logreg)])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "W_3Okn-pltgo",
        "outputId": "a2c14174-32df-465d-c159-2c5f286dc514"
      },
      "source": [
        "# sentence 1\n",
        "cntlog_model1 = cntlog_pipeline.fit(df_train[\"sentence1\"], df_train[\"gold_label\"])\n",
        "\n",
        "train_pred1, test_pred1 = predictions(cntlog_model1, [df_train[\"sentence1\"], df_dev[\"sentence1\"]])\n",
        "\n",
        "pd.DataFrame(classification_report(df_train[\"gold_label\"], train_pred1, output_dict=True))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.336390</td>\n",
              "      <td>0.339281</td>\n",
              "      <td>0.339570</td>\n",
              "      <td>0.33864</td>\n",
              "      <td>0.338414</td>\n",
              "      <td>0.338415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.264353</td>\n",
              "      <td>0.343956</td>\n",
              "      <td>0.407590</td>\n",
              "      <td>0.33864</td>\n",
              "      <td>0.338633</td>\n",
              "      <td>0.338640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.296052</td>\n",
              "      <td>0.341603</td>\n",
              "      <td>0.370484</td>\n",
              "      <td>0.33864</td>\n",
              "      <td>0.336046</td>\n",
              "      <td>0.336052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>8326.000000</td>\n",
              "      <td>8347.000000</td>\n",
              "      <td>8327.000000</td>\n",
              "      <td>0.33864</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...     macro avg  weighted avg\n",
              "precision       0.336390     0.339281  ...      0.338414      0.338415\n",
              "recall          0.264353     0.343956  ...      0.338633      0.338640\n",
              "f1-score        0.296052     0.341603  ...      0.336046      0.336052\n",
              "support      8326.000000  8347.000000  ...  25000.000000  25000.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "4n1bVtc7z7Jw",
        "outputId": "350d238f-c47e-4ef4-83e6-9eb6b3c9f7ce"
      },
      "source": [
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], test_pred1, output_dict=True))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.329217</td>\n",
              "      <td>0.335819</td>\n",
              "      <td>0.325295</td>\n",
              "      <td>0.329913</td>\n",
              "      <td>0.330110</td>\n",
              "      <td>0.330161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.260220</td>\n",
              "      <td>0.338240</td>\n",
              "      <td>0.391963</td>\n",
              "      <td>0.329913</td>\n",
              "      <td>0.330141</td>\n",
              "      <td>0.329913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.290680</td>\n",
              "      <td>0.337025</td>\n",
              "      <td>0.355531</td>\n",
              "      <td>0.329913</td>\n",
              "      <td>0.327745</td>\n",
              "      <td>0.327672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.329913</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.329217     0.335819  ...     0.330110      0.330161\n",
              "recall          0.260220     0.338240  ...     0.330141      0.329913\n",
              "f1-score        0.290680     0.337025  ...     0.327745      0.327672\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "V9o6YIF70L3N",
        "outputId": "51c0e18d-59ff-463e-a7f0-31b59c8e4bd5"
      },
      "source": [
        "#sentence 2\n",
        "cntlog_model2 = cntlog_pipeline.fit(df_train[\"sentence2\"], df_train[\"gold_label\"])\n",
        "\n",
        "train_pred2, test_pred2 = predictions(cntlog_model1, [df_train[\"sentence2\"], df_dev[\"sentence2\"]])\n",
        "\n",
        "pd.DataFrame(classification_report(df_train[\"gold_label\"], train_pred2, output_dict=True))\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.757564</td>\n",
              "      <td>0.732895</td>\n",
              "      <td>0.765762</td>\n",
              "      <td>0.75132</td>\n",
              "      <td>0.752074</td>\n",
              "      <td>0.752058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.733726</td>\n",
              "      <td>0.787948</td>\n",
              "      <td>0.732196</td>\n",
              "      <td>0.75132</td>\n",
              "      <td>0.751290</td>\n",
              "      <td>0.751320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.745455</td>\n",
              "      <td>0.759425</td>\n",
              "      <td>0.748603</td>\n",
              "      <td>0.75132</td>\n",
              "      <td>0.751161</td>\n",
              "      <td>0.751168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>8326.000000</td>\n",
              "      <td>8347.000000</td>\n",
              "      <td>8327.000000</td>\n",
              "      <td>0.75132</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...     macro avg  weighted avg\n",
              "precision       0.757564     0.732895  ...      0.752074      0.752058\n",
              "recall          0.733726     0.787948  ...      0.751290      0.751320\n",
              "f1-score        0.745455     0.759425  ...      0.751161      0.751168\n",
              "support      8326.000000  8347.000000  ...  25000.000000  25000.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "jT5vvrhv0ZAj",
        "outputId": "13ae08b0-37c9-435c-893a-cead56d6b0a3"
      },
      "source": [
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], test_pred2, output_dict=True))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.596813</td>\n",
              "      <td>0.609481</td>\n",
              "      <td>0.602356</td>\n",
              "      <td>0.602926</td>\n",
              "      <td>0.602883</td>\n",
              "      <td>0.602920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.605552</td>\n",
              "      <td>0.617903</td>\n",
              "      <td>0.584853</td>\n",
              "      <td>0.602926</td>\n",
              "      <td>0.602770</td>\n",
              "      <td>0.602926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.601151</td>\n",
              "      <td>0.613663</td>\n",
              "      <td>0.593476</td>\n",
              "      <td>0.602926</td>\n",
              "      <td>0.602763</td>\n",
              "      <td>0.602860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.602926</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.596813     0.609481  ...     0.602883      0.602920\n",
              "recall          0.605552     0.617903  ...     0.602770      0.602926\n",
              "f1-score        0.601151     0.613663  ...     0.602763      0.602860\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgphj_htcR7F"
      },
      "source": [
        "*TODO: Enter your answer to the discussion questions here*\n",
        "\n",
        "**A** From the accuracies obtained, it seems that basing predictions on sentence 2 yields better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5aVDrT4cR7G"
      },
      "source": [
        "## Problem 5: A classifier based on manually engineered features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpuyzLUacR7G"
      },
      "source": [
        "[Bowman et al., 2015](https://www.aclweb.org/anthology/D15-1075/) evaluate a classifier that uses (among others) **cross-unigram features**. This term is used to refer to pairs of unigrams $(w_1, w_2)$ such that $w_1$ occurs in sentence&nbsp;1, $w_2$ occurs in sentence&nbsp;2, and both have been assigned the same part-of-speech tag.\n",
        "\n",
        "Your next task is to implement the cross-unigram classifier. To this end, the next cell contains skeleton code for a transformer that you can use as the first component in a classification pipeline. This transformer converts each row of the SNLI data frame into a space-separated string consisting of\n",
        "\n",
        "* the standard unigrams (of sentence&nbsp;1 or sentence&nbsp;2 – choose whichever performed better in Problem&nbsp;4)\n",
        "* the cross-unigrams, as described above.\n",
        "\n",
        "The space-separated string forms a new &lsquo;document&rsquo; that can be passed to a vectorizer in exactly the same way as a standard sentence in Problem&nbsp;4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-werRWAcR7G"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class CrossUnigramsTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    # Transform a single row of the dataframe.\n",
        "    def _transform(self, row):\n",
        "        # TODO: Replace the following line with your own code\n",
        "        with nlp.disable_pipes(\"tagger\", \"parser\", \"ner\"):\n",
        "            words_tags1 = [(w.text, t) for w, t in zip(nlp(row[1]), row[2].split()) if w.is_alpha and not w.is_stop]\n",
        "            words_tags2 = [(w.text, t) for w, t in zip(nlp(row[3]), row[4].split()) if w.is_alpha and not w.is_stop]\n",
        "\n",
        "        \n",
        "        # Filter out tags that do not match\n",
        "        cross_unigrams = [wt1[0] + \"_\" + wt2[0] for wt1,wt2 in \n",
        "                          itertools.product(words_tags1, words_tags2) if wt1[1]==wt2[1]]\n",
        "        \n",
        "        # Combine standard unigrams and cross unigrams\n",
        "        return \" \".join([w for w, t in words_tags2] + cross_unigrams)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [self._transform(row) for row in X.itertuples()]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbhtmBEWcR7G"
      },
      "source": [
        "Once you have an implementation of the transformer, extend the pipeline that you built for Problem&nbsp;4, train it, and evaluate it on the development data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnwwWJRncR7H",
        "outputId": "db0d5cc7-c43e-4b38-cef6-0951fda8307a"
      },
      "source": [
        "# TODO: Enter code here to implement the cross-unigrams classifier. Print the classification report.\n",
        "cu_vectorizer = CountVectorizer(ngram_range=(1,1))\n",
        "cu_logreg = LogisticRegression(solver=\"saga\", multi_class=\"ovr\", max_iter= 100)\n",
        "cu_transformer = CrossUnigramsTransformer()\n",
        "\n",
        "cu_pipeline = Pipeline([(\"cross_unigram\", cu_transformer), (\"cnt_vectorizer\", cu_vectorizer),  (\"LogisticRegression\", logreg)])\n",
        "cu_logreg_model = cu_pipeline.fit(df_train.loc[:, df_train.columns !=\"gold_label\"], df_train[\"gold_label\"])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81de2Xq66j4c"
      },
      "source": [
        "cu_train_pred, cu_dev_pred = predictions(cu_logreg_model, [df_train.loc[:, df_train.columns != \"gold_label\"], df_dev.loc[:, df_dev.columns != \"gold_label\"]])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "tPO3T1WR698s",
        "outputId": "b1ddff69-9c5e-4f99-bc99-173ba8204293"
      },
      "source": [
        "pd.DataFrame(classification_report(df_train[\"gold_label\"], cu_train_pred, output_dict=True))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.944309</td>\n",
              "      <td>0.888133</td>\n",
              "      <td>0.943044</td>\n",
              "      <td>0.92408</td>\n",
              "      <td>0.925162</td>\n",
              "      <td>0.925132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.930699</td>\n",
              "      <td>0.938780</td>\n",
              "      <td>0.902726</td>\n",
              "      <td>0.92408</td>\n",
              "      <td>0.924068</td>\n",
              "      <td>0.924080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.937455</td>\n",
              "      <td>0.912755</td>\n",
              "      <td>0.922444</td>\n",
              "      <td>0.92408</td>\n",
              "      <td>0.924218</td>\n",
              "      <td>0.924208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>8326.000000</td>\n",
              "      <td>8347.000000</td>\n",
              "      <td>8327.000000</td>\n",
              "      <td>0.92408</td>\n",
              "      <td>25000.000000</td>\n",
              "      <td>25000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...     macro avg  weighted avg\n",
              "precision       0.944309     0.888133  ...      0.925162      0.925132\n",
              "recall          0.930699     0.938780  ...      0.924068      0.924080\n",
              "f1-score        0.937455     0.912755  ...      0.924218      0.924208\n",
              "support      8326.000000  8347.000000  ...  25000.000000  25000.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "kFaKLJhj7R-X",
        "outputId": "ce183ce5-46a4-4bb2-e967-ee025855518a"
      },
      "source": [
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], cu_dev_pred, output_dict=True))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.659797</td>\n",
              "      <td>0.616895</td>\n",
              "      <td>0.619346</td>\n",
              "      <td>0.631782</td>\n",
              "      <td>0.632013</td>\n",
              "      <td>0.631990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.654362</td>\n",
              "      <td>0.688795</td>\n",
              "      <td>0.550232</td>\n",
              "      <td>0.631782</td>\n",
              "      <td>0.631130</td>\n",
              "      <td>0.631782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.657068</td>\n",
              "      <td>0.650866</td>\n",
              "      <td>0.582747</td>\n",
              "      <td>0.631782</td>\n",
              "      <td>0.630227</td>\n",
              "      <td>0.630541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.631782</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.659797     0.616895  ...     0.632013      0.631990\n",
              "recall          0.654362     0.688795  ...     0.631130      0.631782\n",
              "f1-score        0.657068     0.650866  ...     0.630227      0.630541\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TR6Kmxof7cOc"
      },
      "source": [
        "We observe an improvement of 3% compared to the previous iteration of the problem without the cross-unigram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RknS4t1AcR7H"
      },
      "source": [
        "## Problem 6: A classifier based on word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9dozjIfcR7H"
      },
      "source": [
        "Your last task in this lab is to build a classifier for the natural language inference task that uses word embeddings. More specifically, we ask you to implement a vectorizer that represents each sentence as the sum of its word vectors – a representation known as the **continuous bag-of-words**. Thus, given that spaCy&rsquo;s word vectors have 300 dimensions, each sentence will be transformed into a 300-dimensional vector. To represent a sentence pair, the vectorizer should concatenate the vectors for the individual sentences; this yields a 600-dimensional vector. This vector can then be passed to a classifier.\n",
        "\n",
        "The next code cell contains skeleton code for the vectorizer. You will have to implement two methods: one that maps a single sentence to a vector (of length 300), and one that maps a sentence pair to a vector (of length 600)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOHjT-iLcR7I"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class PairedSentenceVectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    # Vectorize a single sentence.\n",
        "    def _transform1(self, sentence):\n",
        "        # TODO: Replace the following line with your own code\n",
        "        vect = [nlp.vocab[w].vector for w in sentence.split()]\n",
        "        return np.sum(vect, axis=0)\n",
        "\n",
        "    # Vectorize a single row of the dataframe.\n",
        "    def _transform2(self, row):\n",
        "        # TODO: Replace the following line with your own code\n",
        "        ind, sentence1, sentence2 = row\n",
        "        return np.concatenate((self._transform1(sentence1), self._transform1(sentence2)), axis=0)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.concatenate(\n",
        "            [self._transform2(row).reshape(1, -1) for row in X.itertuples()]\n",
        "        )"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvi1d2Q-cR7I"
      },
      "source": [
        "Once you have a working implementation, build a pipeline consisting of the new vectorizer and a [multi-layer perceptron classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html). This more powerful (compared to logistic regression) classifier is called for here because we do not specify features by hand (as we did in Problem&nbsp;5), but want to let the model learn a good representation of the data by itself. Use 3&nbsp;hidden layers, each with size 300. It suffices to train the classifier for 8&nbsp;iterations (epochs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOvcq8jqcR7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1714085-5b69-4848-d228-6c746c425e33"
      },
      "source": [
        "# TODO: Enter code here to implement the word embeddings classifier. Print the classification report.\n",
        "\n",
        "train_phrase, dev_phrase = df_train[[\"sentence1\", \"sentence2\"]], df_dev[[\"sentence1\", \"sentence2\"]]\n",
        "\n",
        "cbow_pipeline = Pipeline([(\"vectorizer\", PairedSentenceVectorizer()), (\"clf\", MLPClassifier(hidden_layer_sizes=(300,300,300), max_iter=8, verbose=True))])\n",
        "\n",
        "cbow_model = cbow_pipeline.fit(train_phrase, df_train[\"gold_label\"])\n",
        "training_accuracy = cbow_model.score(train_phrase, df_train[\"gold_label\"])\n",
        "dev_accuracy = cbow_model.score(dev_phrase, df_dev[\"gold_label\"])\n",
        "cbow_pred = cbow_model.predict(dev_phrase)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 1.04980061\n",
            "Iteration 2, loss = 0.91956541\n",
            "Iteration 3, loss = 0.87174646\n",
            "Iteration 4, loss = 0.82190665\n",
            "Iteration 5, loss = 0.77401738\n",
            "Iteration 6, loss = 0.72477684\n",
            "Iteration 7, loss = 0.69592107\n",
            "Iteration 8, loss = 0.64783213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "Tk2EX-xnqkhL",
        "outputId": "0044f834-dbc7-4d22-84b9-88f4fb29b775"
      },
      "source": [
        "print(\"The training accuracy is: \", training_accuracy)\n",
        "print(\"The development accuracy is \", dev_accuracy)\n",
        "\n",
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], cbow_pred, output_dict=True))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is:  0.76448\n",
            "The development accuracy is  0.6465149359886202\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.689237</td>\n",
              "      <td>0.624876</td>\n",
              "      <td>0.635610</td>\n",
              "      <td>0.646515</td>\n",
              "      <td>0.649908</td>\n",
              "      <td>0.649840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.589994</td>\n",
              "      <td>0.754581</td>\n",
              "      <td>0.592581</td>\n",
              "      <td>0.646515</td>\n",
              "      <td>0.645719</td>\n",
              "      <td>0.646515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.635766</td>\n",
              "      <td>0.683630</td>\n",
              "      <td>0.613342</td>\n",
              "      <td>0.646515</td>\n",
              "      <td>0.644246</td>\n",
              "      <td>0.644585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.646515</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.689237     0.624876  ...     0.649908      0.649840\n",
              "recall          0.589994     0.754581  ...     0.645719      0.646515\n",
              "f1-score        0.635766     0.683630  ...     0.644246      0.644585\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BaSK7M3cR7I"
      },
      "source": [
        "## Problem 7: Final evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKt8kdbRcR7I"
      },
      "source": [
        "Once you have working code for all problems, re-run Problems&nbsp;4–6 with the full training data. This will take quite a while (expect approximately 1&;nbsp;hour on Colab). **Make sure to not overwrite your previous results.** What are your results on the full data? How do they differ from the results that you obtained for the smaller training data? How do you interpret this? Summarize your findings in a short text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwPjqpolr1DG",
        "outputId": "3bd48313-1400-40a0-90f4-6920e15a06dc"
      },
      "source": [
        "# Copy of previous code to load all the data\n",
        "final_evaluation = True    # TODO: Set to True for the final evaluation!\n",
        "\n",
        "with bz2.open('train.jsonl.bz2', 'rt') as source:\n",
        "    if final_evaluation:\n",
        "        df_train = pd.read_json(source, lines=True)\n",
        "    else:\n",
        "        df_train = pd.read_json(source, lines=True, nrows=25000)\n",
        "    print('Number of sentence pairs in the training data:', len(df_train))\n",
        "\n",
        "with bz2.open('dev.jsonl.bz2', 'rt') as source:\n",
        "    df_dev = pd.read_json(source, lines=True)\n",
        "    print('Number of sentence pairs in the development data:', len(df_dev))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentence pairs in the training data: 549367\n",
            "Number of sentence pairs in the development data: 9842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_N1prb6rk2B"
      },
      "source": [
        "**Random Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04hJN5I4cR7J"
      },
      "source": [
        "# TODO: Enter your code for the full experiments here\n",
        "dummy_class = DummyClassifier().fit(df_train.loc[:, df_train.columns != \"gold_label\"], df_train[\"gold_label\"])\n",
        "train_predict, dev_predict = predictions(dummy_class, [df_train.loc[:, df_train.columns != \"gold_label\"], df_dev.loc[:, df_dev.columns != \"gold_label\"]])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Z8L5IEwKsPe6",
        "outputId": "88824a9d-38ec-4932-d932-2a0e983a5250"
      },
      "source": [
        "pd.DataFrame(classification_report(train_predict, df_train[\"gold_label\"], output_dict=True))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333868</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333868</td>\n",
              "      <td>0.111289</td>\n",
              "      <td>0.333868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500601</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333868</td>\n",
              "      <td>0.166867</td>\n",
              "      <td>0.500601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>0.0</td>\n",
              "      <td>549367.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333868</td>\n",
              "      <td>549367.000000</td>\n",
              "      <td>549367.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction     entailment  ...      macro avg   weighted avg\n",
              "precision            0.0       1.000000  ...       0.333333       1.000000\n",
              "recall               0.0       0.333868  ...       0.111289       0.333868\n",
              "f1-score             0.0       0.500601  ...       0.166867       0.500601\n",
              "support              0.0  549367.000000  ...  549367.000000  549367.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "zBouP-rHsTOQ",
        "outputId": "a4901fc6-b685-4e3c-bd43-001ae2676696"
      },
      "source": [
        "pd.DataFrame(classification_report(dev_predict, df_dev[\"gold_label\"], output_dict=True))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.112748</td>\n",
              "      <td>0.338244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.505505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>0.168502</td>\n",
              "      <td>0.505505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>0.0</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.338244</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision            0.0     1.000000  ...     0.333333      1.000000\n",
              "recall               0.0     0.338244  ...     0.112748      0.338244\n",
              "f1-score             0.0     0.505505  ...     0.168502      0.505505\n",
              "support              0.0  9842.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djDpiQ9IsbzI"
      },
      "source": [
        "**One sided baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECBgpNv5sh1f"
      },
      "source": [
        "# TODO: Enter code here to implement the one-sentence baselines. Print the classification reports.\n",
        "cntvectorizer = CountVectorizer(ngram_range=(1,2), min_df = 4, max_df=0.9)\n",
        "logreg = LogisticRegression(solver=\"saga\", multi_class=\"ovr\", max_iter=100)\n",
        "\n",
        "cntlog_pipeline = Pipeline([(\"cnt_vectorizer\", cntvectorizer), (\"LogisticRegression\", logreg)])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "v5J0tuE8sojm",
        "outputId": "d902620c-ac4d-427b-943a-0805a894026d"
      },
      "source": [
        "# sentence 1\n",
        "cntlog_model1 = cntlog_pipeline.fit(df_train[\"sentence1\"], df_train[\"gold_label\"])\n",
        "\n",
        "train_pred1, test_pred1 = predictions(cntlog_model1, [df_train[\"sentence1\"], df_dev[\"sentence1\"]])\n",
        "\n",
        "pd.DataFrame(classification_report(df_train[\"gold_label\"], train_pred1, output_dict=True))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.337035</td>\n",
              "      <td>0.339024</td>\n",
              "      <td>0.338615</td>\n",
              "      <td>0.338359</td>\n",
              "      <td>0.338224</td>\n",
              "      <td>0.338224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.256978</td>\n",
              "      <td>0.361097</td>\n",
              "      <td>0.397108</td>\n",
              "      <td>0.338359</td>\n",
              "      <td>0.338394</td>\n",
              "      <td>0.338359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.291612</td>\n",
              "      <td>0.349712</td>\n",
              "      <td>0.365536</td>\n",
              "      <td>0.338359</td>\n",
              "      <td>0.335620</td>\n",
              "      <td>0.335603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>183187.000000</td>\n",
              "      <td>183416.000000</td>\n",
              "      <td>182764.000000</td>\n",
              "      <td>0.338359</td>\n",
              "      <td>549367.000000</td>\n",
              "      <td>549367.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction     entailment  ...      macro avg   weighted avg\n",
              "precision       0.337035       0.339024  ...       0.338224       0.338224\n",
              "recall          0.256978       0.361097  ...       0.338394       0.338359\n",
              "f1-score        0.291612       0.349712  ...       0.335620       0.335603\n",
              "support    183187.000000  183416.000000  ...  549367.000000  549367.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "CPYVYEpBsv2-",
        "outputId": "ae8a6c0a-e412-406a-f70c-e95a645b8363"
      },
      "source": [
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], test_pred1, output_dict=True))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.335438</td>\n",
              "      <td>0.342477</td>\n",
              "      <td>0.330064</td>\n",
              "      <td>0.335907</td>\n",
              "      <td>0.335993</td>\n",
              "      <td>0.336053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.259304</td>\n",
              "      <td>0.363773</td>\n",
              "      <td>0.384853</td>\n",
              "      <td>0.335907</td>\n",
              "      <td>0.335977</td>\n",
              "      <td>0.335907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.292498</td>\n",
              "      <td>0.352804</td>\n",
              "      <td>0.355359</td>\n",
              "      <td>0.335907</td>\n",
              "      <td>0.333554</td>\n",
              "      <td>0.333558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.335907</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.335438     0.342477  ...     0.335993      0.336053\n",
              "recall          0.259304     0.363773  ...     0.335977      0.335907\n",
              "f1-score        0.292498     0.352804  ...     0.333554      0.333558\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "k1eE12pws1VP",
        "outputId": "0780248d-aa7f-406d-c7f0-f34290605b6d"
      },
      "source": [
        "#sentence 2\n",
        "cntlog_model2 = cntlog_pipeline.fit(df_train[\"sentence2\"], df_train[\"gold_label\"])\n",
        "\n",
        "train_pred2, test_pred2 = predictions(cntlog_model1, [df_train[\"sentence2\"], df_dev[\"sentence2\"]])\n",
        "\n",
        "pd.DataFrame(classification_report(df_train[\"gold_label\"], train_pred2, output_dict=True))\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.736777</td>\n",
              "      <td>0.708316</td>\n",
              "      <td>0.751960</td>\n",
              "      <td>0.731107</td>\n",
              "      <td>0.732351</td>\n",
              "      <td>0.732326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.719265</td>\n",
              "      <td>0.773422</td>\n",
              "      <td>0.700510</td>\n",
              "      <td>0.731107</td>\n",
              "      <td>0.731066</td>\n",
              "      <td>0.731107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.727916</td>\n",
              "      <td>0.739439</td>\n",
              "      <td>0.725324</td>\n",
              "      <td>0.731107</td>\n",
              "      <td>0.730893</td>\n",
              "      <td>0.730901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>183187.000000</td>\n",
              "      <td>183416.000000</td>\n",
              "      <td>182764.000000</td>\n",
              "      <td>0.731107</td>\n",
              "      <td>549367.000000</td>\n",
              "      <td>549367.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction     entailment  ...      macro avg   weighted avg\n",
              "precision       0.736777       0.708316  ...       0.732351       0.732326\n",
              "recall          0.719265       0.773422  ...       0.731066       0.731107\n",
              "f1-score        0.727916       0.739439  ...       0.730893       0.730901\n",
              "support    183187.000000  183416.000000  ...  549367.000000  549367.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "9BxWAYqss7fe",
        "outputId": "a19a65d8-2050-47a4-da98-9012dd011bd4"
      },
      "source": [
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], test_pred2, output_dict=True))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.666871</td>\n",
              "      <td>0.674068</td>\n",
              "      <td>0.680013</td>\n",
              "      <td>0.673542</td>\n",
              "      <td>0.673651</td>\n",
              "      <td>0.673625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.662599</td>\n",
              "      <td>0.711325</td>\n",
              "      <td>0.645750</td>\n",
              "      <td>0.673542</td>\n",
              "      <td>0.673224</td>\n",
              "      <td>0.673542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.664728</td>\n",
              "      <td>0.692195</td>\n",
              "      <td>0.662439</td>\n",
              "      <td>0.673542</td>\n",
              "      <td>0.673121</td>\n",
              "      <td>0.673266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.673542</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.666871     0.674068  ...     0.673651      0.673625\n",
              "recall          0.662599     0.711325  ...     0.673224      0.673542\n",
              "f1-score        0.664728     0.692195  ...     0.673121      0.673266\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJn7CfE0tHs-"
      },
      "source": [
        "**A classifier based on manually engineered features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsHHJKTztJnn",
        "outputId": "43931cda-a1a8-4146-96b1-e882b5f91423"
      },
      "source": [
        "cu_vectorizer = CountVectorizer(ngram_range=(1,1))\n",
        "cu_logreg = LogisticRegression(solver=\"saga\", multi_class=\"ovr\", max_iter= 100)\n",
        "cu_transformer = CrossUnigramsTransformer()\n",
        "\n",
        "cu_pipeline = Pipeline([(\"cross_unigram\", cu_transformer), (\"cnt_vectorizer\", cu_vectorizer),  (\"LogisticRegression\", logreg)])\n",
        "cu_logreg_model = cu_pipeline.fit(df_train.loc[:, df_train.columns !=\"gold_label\"], df_train[\"gold_label\"])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyrBkCIptOv3"
      },
      "source": [
        "cu_train_pred, cu_dev_pred = predictions(cu_logreg_model, [df_train.loc[:, df_train.columns != \"gold_label\"], df_dev.loc[:, df_dev.columns != \"gold_label\"]])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "N0f-reVFtS7G",
        "outputId": "5bc55246-e2bf-4c47-fed0-f4e5cac76e54"
      },
      "source": [
        "pd.DataFrame(classification_report(df_train[\"gold_label\"], cu_train_pred, output_dict=True))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.877254</td>\n",
              "      <td>0.797701</td>\n",
              "      <td>0.867547</td>\n",
              "      <td>0.844332</td>\n",
              "      <td>0.847501</td>\n",
              "      <td>0.847465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.845950</td>\n",
              "      <td>0.900919</td>\n",
              "      <td>0.785921</td>\n",
              "      <td>0.844332</td>\n",
              "      <td>0.844263</td>\n",
              "      <td>0.844332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.861318</td>\n",
              "      <td>0.846174</td>\n",
              "      <td>0.824719</td>\n",
              "      <td>0.844332</td>\n",
              "      <td>0.844070</td>\n",
              "      <td>0.844086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>183187.000000</td>\n",
              "      <td>183416.000000</td>\n",
              "      <td>182764.000000</td>\n",
              "      <td>0.844332</td>\n",
              "      <td>549367.000000</td>\n",
              "      <td>549367.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction     entailment  ...      macro avg   weighted avg\n",
              "precision       0.877254       0.797701  ...       0.847501       0.847465\n",
              "recall          0.845950       0.900919  ...       0.844263       0.844332\n",
              "f1-score        0.861318       0.846174  ...       0.844070       0.844086\n",
              "support    183187.000000  183416.000000  ...  549367.000000  549367.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "bTf6x-kitbxe",
        "outputId": "ca626e95-b015-4371-9b14-f83cbb557d0a"
      },
      "source": [
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], cu_dev_pred, output_dict=True))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.761410</td>\n",
              "      <td>0.711223</td>\n",
              "      <td>0.730170</td>\n",
              "      <td>0.732981</td>\n",
              "      <td>0.734268</td>\n",
              "      <td>0.734166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.737950</td>\n",
              "      <td>0.807149</td>\n",
              "      <td>0.651623</td>\n",
              "      <td>0.732981</td>\n",
              "      <td>0.732241</td>\n",
              "      <td>0.732981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.749497</td>\n",
              "      <td>0.756156</td>\n",
              "      <td>0.688664</td>\n",
              "      <td>0.732981</td>\n",
              "      <td>0.731439</td>\n",
              "      <td>0.731754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.732981</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.761410     0.711223  ...     0.734268      0.734166\n",
              "recall          0.737950     0.807149  ...     0.732241      0.732981\n",
              "f1-score        0.749497     0.756156  ...     0.731439      0.731754\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNQSWqE7thxe"
      },
      "source": [
        "**A classifier based on word embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9alfOGdtoH-",
        "outputId": "bc263cfa-0432-4a22-e942-4519dc1315c8"
      },
      "source": [
        "train_phrase, dev_phrase = df_train[[\"sentence1\", \"sentence2\"]], df_dev[[\"sentence1\", \"sentence2\"]]\n",
        "\n",
        "cbow_pipeline = Pipeline([(\"vectorizer\", PairedSentenceVectorizer()), (\"clf\", MLPClassifier(hidden_layer_sizes=(300,300,300), max_iter=8, verbose=True))])\n",
        "\n",
        "cbow_model = cbow_pipeline.fit(train_phrase, df_train[\"gold_label\"])\n",
        "training_accuracy = cbow_model.score(train_phrase, df_train[\"gold_label\"])\n",
        "dev_accuracy = cbow_model.score(dev_phrase, df_dev[\"gold_label\"])\n",
        "cbow_pred = cbow_model.predict(dev_phrase)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.79740871\n",
            "Iteration 2, loss = 0.68328956\n",
            "Iteration 3, loss = 0.64326345\n",
            "Iteration 4, loss = 0.61644263\n",
            "Iteration 5, loss = 0.59521074\n",
            "Iteration 6, loss = 0.57762891\n",
            "Iteration 7, loss = 0.56330906\n",
            "Iteration 8, loss = 0.55010570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "NQjmap0Rtxy2",
        "outputId": "07b86e59-6f05-4406-de9d-d1c9213e319d"
      },
      "source": [
        "print(\"The training accuracy is: \", training_accuracy)\n",
        "print(\"The development accuracy is \", dev_accuracy)\n",
        "\n",
        "pd.DataFrame(classification_report(df_dev[\"gold_label\"], cbow_pred, output_dict=True))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is:  0.7881798506280865\n",
            "The development accuracy is  0.7653932127616339\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contradiction</th>\n",
              "      <th>entailment</th>\n",
              "      <th>neutral</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.833865</td>\n",
              "      <td>0.768300</td>\n",
              "      <td>0.706663</td>\n",
              "      <td>0.765393</td>\n",
              "      <td>0.769609</td>\n",
              "      <td>0.769877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.718121</td>\n",
              "      <td>0.819766</td>\n",
              "      <td>0.757342</td>\n",
              "      <td>0.765393</td>\n",
              "      <td>0.765076</td>\n",
              "      <td>0.765393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.771677</td>\n",
              "      <td>0.793199</td>\n",
              "      <td>0.731125</td>\n",
              "      <td>0.765393</td>\n",
              "      <td>0.765333</td>\n",
              "      <td>0.765627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>3278.000000</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>3235.000000</td>\n",
              "      <td>0.765393</td>\n",
              "      <td>9842.000000</td>\n",
              "      <td>9842.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           contradiction   entailment  ...    macro avg  weighted avg\n",
              "precision       0.833865     0.768300  ...     0.769609      0.769877\n",
              "recall          0.718121     0.819766  ...     0.765076      0.765393\n",
              "f1-score        0.771677     0.793199  ...     0.765333      0.765627\n",
              "support      3278.000000  3329.000000  ...  9842.000000   9842.000000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxLR5q-XcR7J"
      },
      "source": [
        "*TODO: Insert your discussion of the experimental results here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5t1WxSYcR7J"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "    Please read the section ‘General information’ on the ‘Labs’ page of the course website before submitting this notebook!\n",
        "</div>"
      ]
    }
  ]
}